
\chapter[Choosing transcriptomics analyses]{Choosing reliable, reproducible 
           transcriptomics analyses}\label{chapter:intro3}

Throughout this dissertation, I present analyses of the expression of the genomes
of human cells or tissues of mice that have been treated 
with \textit{C. difficile} toxins A and B
(TcdA and TcdB) in order to determine the pathogenic responses
of the host at the cellular level. 
In learning how to process this type of data,
I encountered many limitations and misunderstandings in 
common gene expression analyses. In this chapter, I describe
the background of this type of data and data analyses that form 
the base of this dissertation, and explain some important considerations
for interpreting sometimes very different results 
produced by different data analyses, an overlooked problem in the
majority of gene expression studies.

\section{Background}

\subsection{mRNA as a measure of cell state}

Our genomes are a sequence of $\sim$3-billion ``letters'' from a four-letter
alphabet of nucleobase molecules (\textit{bases}) \cite{Lander:2001wi}. 
Each of our $\sim$20,000 genes is pieced together from, on average,
5 physically separate sequences called \textit{exons}. Exons, which
range from $\sim$20 to 1,600 bases, are contained
within one of the 46 strands of DNA in our cells \cite{Michael:1999dm}.

The central dogma of molecular biology is 
DNA $\rightarrow$ RNA $\rightarrow$ protein \cite{Crick:1970wb}.
In each cell, exons are
copied (\textit{transcribed}) and spliced into portable
messenger RNA (mRNA). 
mRNA is then \textit{translated} to strings
of amino acids that arrange themselves into shapes with 
chemical properties that perform specific tasks.
These amino acid strings, or proteins, are the primary functional 
units that execute the instructions in our DNA.

When a protein is needed, a cell's ``circuitry'' 
triggers a gene (the DNA encoding that protein)
to be transcribed to mRNA that is then translated to the protein.
Specific amounts of proteins are produced
in response to different stimuli. Since the proteins will alter
the physical state of cells and consequently the body's overall physiological responses, 
many scientists have striven to understand the arrangement and logic
of this regulatory circuitry.

Most of this circuit's components were identified soon after the
sequencing of the human genome in 2003 \cite{Consortium:2004bm,Gregory:2006tu}.
This and decades of previous biological research provided a very basic view
of connections within the cell, yet many of the studies delineating
functions were limited to small sets of genes and proteins.
To be able to understand how all the components affect each other,
there had to be a way to take snapshots of the levels of thousands more 
mRNAs or proteins.

In 1982, technology to simultaneously measure
genome-wide gene expression (i.e., the levels of mRNA in a cell)
from a collection of cells was already being developed \cite{Augenlicht:1982wo}. 
Current RNA sequencing technologies
can now count individual mRNA molecules (\textit{transcripts}) from a collection of cells
for \${}1000 or less.

\subsection{Measuring mRNA levels with microarrays}

DNA molecules consist of two, connected, parallel strands, each strand 
containing a sequence of nucleobases along a sugar backbone.
The four bases (adenosine (A), thymine (T), cytosine (C), guanine (G))
join to each other by hydrogen bonds. A only pairs with T; C only pairs with G.
When two strands are aligned so that the base pairs match, the two strands
\textit{hybridize}.

Strand-specific hybridization can be used to identify
DNA sequences from uncharacterized samples. For example, single-stranded DNA
with a known sequence
can be fixed to a substrate or surface, and DNA from an unknown
source can then be labeled and washed over that surface.
If DNA from the two sources have matching strands (i.e., they
\textit{complement} one another), the labeled
DNA will hybridize and be detected.
The first ``gene arrays'' that could detect multiple sequences in this way
were built by attaching 
DNA to hundreds of spots (\textit{probes}) on glass plates or 
slides \cite{Maskos:1992co, Augenlicht:1982wo}.
Each probe contained thousands or millions of DNA 
molecules with the same sequence so that one gene was detected per probe.

Since hybridization requires two DNA samples, mRNA must
be reverse transcribed back to DNA if it is to be measured on a gene array.
The resulting complementary DNA (cDNA)
can then be labeled and detected.
Signal intensities from the probes indicate the relative amounts of each
mRNA in a sample.


Microarrays, very small gene arrays, were introduced in 1995 \cite{Schena:1995fy}. 
Although microarrays require more sophisticated
manufacturing, they are based on the principles of older gene arrays.


\section[Microarray preprocessing]{Microarray preprocessing techniques}

The most commonly used microarrays over the past decade
have been made by Affymetrix. I described here many methods
designed for these arrays, yet the principles can be extended to
most other microarray technologies and even sequencing data.

\subsection{Steps of data preprocessing}

\subsubsection{Affymetrix microarrays}

In less than one square inch, Affymetrix arrays fit over one million probes, enough
to measure genome-wide expression (the \textit{transcriptome}).
Since exons are usually much longer than the 25-nucleotide probes,
\textit{probe sets} of ten to fifteen probes are designed to hybridize
one gene or exon.

\subsubsection{Nonspecific hybridization}

For each probe, Affymetrix made another
\textit{mismatch} probe with the 13\textsuperscript{th} 
base changed. 
By subtracting the mismatch signal from the \textit{perfect-match} signal,
\textit{nonspecific hybridization} from other transcripts may be 
estimated (\textit{perfect match correction}).
However, mismatch hybridization is far more complex than this.
Usually, more than one third of mismatch probes have a higher
signal than their perfect match probes \cite{Irizarry:2003ge}. 
This should theorectically never happen. Several have proposed
hierarchical models with nonlinear terms that
better account for mismatch probes 
\cite{Li:2001jv,Milo:2003tt,Liu:2005ey,Hein:2005ip}, yet algorithms
that ignore mismatch probes perform equally
well or better \cite{Chen:2007cr,Irizarry:2003ge,Hochreiter:2006ja}.

\subsubsection{Background correction}

Since mismatch probes cannot be used and there is no 
empty space on high-density arrays, 
background signals must be estimated from many
probes. Affymetrix first proposed splitting an array
into zones and calculating background signals from low
intensity probes. This approach systematically corrects large
sections of the array,
yet it does not address probe-specific background signals.

Taking a statistical approach, 
Irizarry et al. observed the distribution
of all observed probe signals ($O$) could be approximated by
a mixture of an exponential distribution ($S$) and a
normal distribution ($B$) \cite{Irizarry:2003ge}.
$S$ and $B$ were considered the true signal and background signal, respectively ($O=S+B$).
After the mean and variance of $S$ and $B$ are estimated from the data, 
the background-corrected signal can be calculated 
as $\text{E}[S|O=o]$ by the robust multi-array average (RMA) procedure in
\cite{Irizarry:2003ge}. 
Wu et al. introcuded gcRMA, which improved upon RMA by 
accounting for sequence-specific probe
affinities that were determined from previous experiments
($O=S+B+N$ where $N$ is non-specific hybridization due to
differences in probe sequences) \cite{Wu:2004wh}. gcRMA
also modeled mismatch probes by making two equations, one for 
$O_{\text{mismatch}}$ and one for $O_{\text{perfect}}$, with one common 
term, the true signal $S$. 
Similarly, other model-based expression value calculations
have the option to include or ignore
mismatch probes (e.g.,\cite{Li:2001jv,Milo:2003tt}).

\subsubsection{Probe set summarization}

To get a gene's expression value, the probes in a probe
set must be summarized. 
Since outliers are common, robust
statistics (e.g., median) are preferred.
Affymetrix first recommended the Tukey bi-weight
statistic, calculating probe set values one microarray at a time.
However, many probes have similar effects across all microarrays
(e.g., different affinities), and these \textit{probe effects} can 
be modeled and removed to increase precision as was shown by Li and Wong 
(\cite{Li:2001jv,Li:2001wk} is often called the ``Li-Wong method'').
The most popular summarization, ``median polish'', places a probe set's expression
values $a_{ij}$ in a matrix ($i$ indicates the probe an $j$ 
indicates the array). The row and column medians are 
iteratively subtracted to estimate an error matrix. Probe effects and
expression values are calculated from the sum of the subtracted row 
and column medians, respectively, minus the 
medians of both vector sums \cite{Mosteller:1977vp,Irizarry:2003ge}.  
Chen et al.'s ``distribution-free, weighted'' summarization
accounts for probe effects primarily by assuming that low-variability
probes are high-quality and should be weighted more 
than other probes \cite{Chen:2007cr}.
Hochreiter et al. assume perfect match probes are normally distributed, enabling
them to perform `factor analysis' 
where the `factors'
are considered normalized concentrations of mRNA \cite{Hochreiter:2006ja}. 
Even more complex models may incorporate 
background correction, perfect-match correction, and probe set summarization
into one step, yet each step is typically performed separately.

\subsubsection{Normalization}

Systematic differences between arrays must be normalized if they
are to be compared. The simplest normalization procedures center
all array values by mean, median, or some other measure, yet centering
doesn't account for different ranges of values.
Quantile normalization forces two arrays to have the exact same
statistical distribution \cite{Bolstad:2003ia}. Li and Wong's normalization
iteratively searches for a group of ``householding genes'' (the invariant 
set of probes) that will be forced to the same expression values in all arrays,
and all other probes are adjusted accordingly \cite{Li:2001wk}.
Huber et al. found that the inverse hypberbolic sine transformation
of array data made a probe's variance across arrays 
less dependent on its mean \cite{Huber:2003bw}.
This variance stabilization---in combination with a nonlinear model that is fit to find
scaling factors and offsets for each microarray---is used for normalization.
Loess normalization applies a smoother to an `MA plot' which plots
the differences between two arrays ($M=log_2(x_1/x_2)=log_2(x_1)-log_2(x_2)$)
versus the average signal of two arrays ($A=\frac{1}{2}log_2(x_1x_2)=\frac{1}{2}(log_2(x_1)+log_2(x_2))$).
The smoother is subtracted from each point so that the plot
is centered around the $A$-axis. Loess normalization thus makes
offset adjustments that are dependent on the intensity of the signal.

\subsection{Order and necessity of analysis steps}

All microarray preprocessing steps are optional.
 
If one is sure of impeccable sample isolation and
reproducibility, they might decide against normalization. 
This rarely happens in practice. Only in some
\textit{in vitro} experiments performed at the same time by the same person
are samples so similar that skipping normalization might be unnecessary.
However, even the slightest differences in one of many experimental steps 
(e.g., scanner reproducibility, mRNA concentratioin calculations, hybridization
temperatures) usually cause systematic errors that require normalization.
There should be strong justification for skipping normalization.

Background correction algorithms essentially deconvolute the observed
signal into two signals: the noise and true signal.
They are most helpful then for low-signal probes where
the signal to noise ratio is lowest. If one is only interested in
probes with the highest signal, they might consider skipping
background correction. After all, background correction is a model, and models
are always wrong.

One may trust that mismatch probes entirely account for
background signals and nonspecific hybridization. 
However, mismatch and perfect match
probes are usually correlated, indicating that mismatch probes still
weakly detect the target transcript. Therefore mismatch probes should
be ignored or included as a factor in statistical models that perform
background correction.

Probe set summarization may even be skipped, and expression values
for 500,000+ probes reported by aligning each probe to a gene. Summarization
reduces 10+ probes to one value, so 90\% of the information content
is lost. With so much focus on data reduction, this
dramatic loss in information is overlooked. Before summarization, one might use
the distribution of probe values to perform more powerful statistical tests or to propogate
error through subsequent analyses \cite{Milo:2003tt,Liu:2005ey}.
Nevertheless, probe set summarization must eventually be performed
at some level if one wants to study genes, not 25-nucleotide stretches of DNA.

There is no strict requirement for the order of the steps are performed,
yet there are limitiations. For instance, if probe set summarization were done first,
then background summarization could not use the probe values to estimate
the distribution of noise in the array. Perfect-match correction also wouldn't
be possible. Probe set summarization is usually the last step, and background
correction is the first.

Normalization can be applied before and/or after summarization.
There is no strong evidence supporting one choice.
It is also unclear if normalization should be done for all arrays at once
or separately for subsets (e.g., control and treatment groups).

\section{Choosing preprocessing techniques}

\subsection{Which preprocessing steps should I choose?}

There is no good answer. Over ten years of 

\subsection{Interpreting processed microarray data}

some work for better output. correlation with RMA versus gcRMA
gcRMA sacrifices precision for better accuracy

\subsubsection{How data processing affects results}

The truth is that some work better for detecting levels, some
better account for low intensity variation, some find a way use the mismatch
information to gain a slight boost in accuracy. There is no best way.




\section[Differential expression]{Detecting differentially expressed genes}


\section{Caveats of microarrays and alternatives}

\section{Future improvements in transcriptomics analyses}


\subsection{reproducibility}

\subsection{visualization}